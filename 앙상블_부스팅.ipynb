{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble - Boosting Model\n",
    "- 부스팅(Boosting)이란? \n",
    "    - 단순하고 약한 학습기(Weak Learner)들을 결합해 강력한 학습기(Strong Learner)를 만드는 방식\n",
    "    - 정확도가 낮은 하나의 모델을 만들어 학습 시킨뒤, 모델의 예측 오류는 두번째 모델이 보완, 이 두 모델을 합치면 처음보다 정확한 모델이 만들어짐\n",
    "    - 합쳐진 모델의 예측 오류는 다음 모델에서 보완하여 계속 더하는 과정을 반복\n",
    "    - **약한 학습기들은 앞 학습기가 만든 오류를 줄이는 방향으로 학습**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientBoosting\n",
    "- 개별 모델로 DecisionTree를 사용\n",
    "- depth가 깊지 않은 트리를 많이 연결해 이전 트리의 오차를 보정하는 방식\n",
    "- 각 모델들은 아의 모델이 틀린 오차를 학습해 전체 오차가 감소하도록 학습\n",
    "- 얕은 트리를 많이 연결하여 각각의 트리가 데이터의 일부에 대해 예측을 잘 수행하도록 하고 그런 트리들이 모여 전체 성능을 높이는 것이 기본 아이디어\n",
    "- 분류와 회귀 둘다 지원(GradientBoostingClassifier, GradientBoostingRegressor)\n",
    "- 훈련시간이 많이 걸리고, 트리기반 모델의 특성상 희소한 고차원 데이터에서는 성능이 떨어지는 단점이 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoosting 학습 및 추론 프로세스\n",
    "**학습데이터**\n",
    "![image](https://blog.kakaocdn.net/dn/ccTuma/btqy7qdVwBg/TeNk9QgE03gu6AWt9VWjl1/img.png)\n",
    "- 키, 좋아하는 색, 성별로 몸무게를 예측하는 모델을 생성\n",
    "    - Feature: Height(m), Favorite Color, Gender\n",
    "    - Target: Weight(kg)\n",
    "\n",
    "![image](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FSsgry%2Fbtqxmv2OFmy%2FXUPZ3FfKyQHOywaZ9sF9P0%2Fimg.png)\n",
    "![image](https://blog.kakaocdn.net/dn/bM5ezy/btqxonpsQPx/fCYzXJ0Yh2R0oq59PCAu90/img.png)\n",
    "- 평균으로 예측\n",
    "- Residual(잔차)을 계산\n",
    "    - Residual(잔차): 정답과 예측결과 간의 차이\n",
    "    - 여기서는 정답과 평균으로 예측한 결과간의 차이를 계산\n",
    "\n",
    "![image](https://blog.kakaocdn.net/dn/ckdStN/btqxmMDggSx/26GkeR7fyKMLKjvrrxdBtk/img.png)\n",
    "![image](https://blog.kakaocdn.net/dn/YzhKx/btqxpAVVNtU/PKVP5RKXUnzWViVOBJLISk/img.png)\n",
    "- 첫번째 DecisionTree 모델은 잔차를 예측하도록 학습한다.\n",
    "    - Features를 입력으로 받아 잔차(Residual)를 예측\n",
    "\n",
    "![image](https://blog.kakaocdn.net/dn/Em0mM/btqxmLdgX2u/vArI6Ceu4l81siY2bXkmo1/img.png)\n",
    "- 위 그림에서 첫 모델이 예측한 첫번째 Datapoint에 대한 잔차 에측결과는 16.8이 나온다\n",
    "- 그것을 첫 번째 예측 값인 71.2에 더하면 정답인 88이 나온다\n",
    "\n",
    "![image](https://blog.kakaocdn.net/dn/tSgXA/btqxpziqfgF/0U5j1866oknp2wHiPdQPeK/img.png)\n",
    "- 예측한 잔차를 그래로 더하면 학습데이터의 값은 100% 예측하겠지만 새로운 데이터에는 맞지 않을 가능성이 높다(Overfitting)\n",
    "- **모델이 예측한 잔차(오차)에 학습율을 곱한 값을 예측 값에 더한다**\n",
    "- **학습율(Learning Rate)**\n",
    "    - 하이퍼파라미터로 오차를 보정하는 비율\n",
    "- 위 예를 보면 처음 예측한 71.2가 72.9로 실제 값에 좀 더 가까이 예측\n",
    "\n",
    "![image](https://blog.kakaocdn.net/dn/ogU9k/btqxoQZeUx6/zUcRNzNizYWvhN2IccRdu0/img.png)\n",
    "- 두번째 DecisionTree 모델은 남은 잔차를 예측하도록 학습\n",
    "- 각 DecisionTree 모델들은 아의 모델들까지 예측한 결과에 대한 잔차를 예측하도록 학습\n",
    "    - 앞의 모델까지 예측한 값에 현재 모델이 예측한 잔차*학습율의 값을 더해 계속 보정해 나간다\n",
    "        - 앞 모델까지 예측한 값 + 학습율*잔차 예측값 = 새 예측값\n",
    "- 위 작업을 반복하여 잔차를 줄인다\n",
    "\n",
    "![image](https://blog.kakaocdn.net/dn/mLlRQ/btqxpA2H9B6/FUbeNKDOBriocbys3V3nTk/img.png)\n",
    "- 새로운 데이터 예측\n",
    "    - 생성된 트리 모델들을 거치면서 마지막에 출력된 결과가 예측 값이 된다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 주요 파라미터\n",
    "- **DecisionTree의 가지치기 관련 매개변수**\n",
    "    - 각각의 DecisionTree가 복잡한 모델이 되지 않도록 한다\n",
    "- **learning rate**\n",
    "    - 이전 DecisionTree의 오차를 얼마나 강하게 보정할 것인지 제어하는 값\n",
    "    - 값이 크면 보정을 강하게 하여 복잡한 모델을 만든다. 학습데이터의 정확도는 올라가지만 과대적합이 날 수 있다\n",
    "    - 값을 작게 하면 보정을 약하게 하여 모델의 복잡도를 줄인다. 과대적합을 줄일 수 있지만 성능 자체가 낮아질 수 있다\n",
    "    - 기본값 : 0.1\n",
    "- **n_estimators**\n",
    "    - DecisionTree의 개수 지정. 많을수록 복잡한 모델\n",
    "- **n_iter_no_change, validation_fraction**\n",
    "    - validation_fraction에 지정한 비율만큼 n_iter_no_change에 지정한 반복 횟수동안 검증점수가 좋아지지 않으면 훈련을 조기 종료\n",
    "- **보통 max_depth를 낮춰 개별 DecisionTree의 복잡도를 낮춘다. 보통 5가 넘지 않게 설정. n_estimators를 가용시간, 메모리 한도에 맞게 크게 설정하고 적절한 learning_rate를 찾는다**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 위스콘신 유방암 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = load_breast_cancer(return_X_y = True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoostingClassifier 모델 생성, 학습, 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb = GradientBoostingClassifier(random_state = 0)\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "train_pred = gb.predict(X_train)\n",
    "test_pred = gb.predict(X_test)\n",
    "\n",
    "train_proba = gb.predict_proba(X_train)[:, 1]\n",
    "test_proba = gb.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "정확도(accuracy): 1.0\n",
      "재현율/민감도(recall): 1.0\n",
      "정밀도(precision): 1.0\n",
      "F1-score: 1.0\n",
      "==============================\n",
      "Test set\n",
      "정확도(accuracy): 0.958041958041958\n",
      "재현율/민감도(recall): 0.9555555555555556\n",
      "정밀도(precision): 0.9772727272727273\n",
      "F1-score: 0.9662921348314608\n"
     ]
    }
   ],
   "source": [
    "# 평가 \n",
    "from metrics import print_metrics_classification as pmc1, print_metrics_classification2 as pmc2\n",
    "\n",
    "pmc1(y_train, train_pred, 'Train set')\n",
    "print('='*30)\n",
    "pmc1(y_test, test_pred, 'Test set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Average Precision: 1.0\n",
      "roc_auc: 1.0\n",
      "==============================\n",
      "test set\n",
      "Average Precision: 0.9741338688529869\n",
      "roc_auc: 0.9776729559748428\n"
     ]
    }
   ],
   "source": [
    "pmc2(y_train, train_proba, 'Train set')\n",
    "print('=' * 30)\n",
    "pmc2(y_test, test_proba, 'test set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature 중요도 조회"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22    0.494771\n",
       "27    0.162170\n",
       "20    0.131205\n",
       "7     0.075635\n",
       "21    0.043937\n",
       "23    0.019981\n",
       "13    0.013616\n",
       "1     0.012091\n",
       "26    0.009072\n",
       "17    0.008441\n",
       "11    0.006200\n",
       "24    0.004643\n",
       "15    0.004200\n",
       "28    0.003383\n",
       "10    0.002465\n",
       "6     0.002308\n",
       "8     0.001918\n",
       "25    0.001776\n",
       "14    0.001356\n",
       "0     0.000240\n",
       "2     0.000179\n",
       "16    0.000160\n",
       "3     0.000105\n",
       "12    0.000058\n",
       "18    0.000034\n",
       "9     0.000023\n",
       "29    0.000017\n",
       "5     0.000013\n",
       "4     0.000005\n",
       "19    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.Series(gb.feature_importances_).sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### learning rate 변화에 따른 성능 변화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = 1\n",
    "n_estimators= 10000\n",
    "lr1 = 0.0001\n",
    "lr2 = 0.001\n",
    "lr3 = 0.01\n",
    "lr4 = 0.1\n",
    "lr5 = 0.5\n",
    "\n",
    "gb_lr1 = GradientBoostingClassifier(n_estimators = n_estimators, max_depth = max_depth, learning_rate = lr1, random_state=0)\n",
    "gb_lr2 = GradientBoostingClassifier(n_estimators = n_estimators, max_depth = max_depth, learning_rate = lr2, random_state=0)\n",
    "gb_lr3 = GradientBoostingClassifier(n_estimators = n_estimators, max_depth = max_depth, learning_rate = lr3, random_state=0)\n",
    "gb_lr4 = GradientBoostingClassifier(n_estimators = n_estimators, max_depth = max_depth, learning_rate = lr4, random_state=0)\n",
    "gb_lr5 = GradientBoostingClassifier(n_estimators = n_estimators, max_depth = max_depth, learning_rate = lr5, random_state=0)\n",
    "\n",
    "\n",
    "gb_lr1.fit(X_train, y_train)\n",
    "gb_lr2.fit(X_train, y_train)\n",
    "gb_lr3.fit(X_train, y_train)\n",
    "gb_lr4.fit(X_train, y_train)\n",
    "gb_lr5.fit(X_train, y_train)\n",
    "\n",
    "train_pred_lr1 = gb_lr1.predict(X_train)\n",
    "train_pred_lr2 = gb_lr2.predict(X_train)\n",
    "train_pred_lr3 = gb_lr3.predict(X_train)\n",
    "train_pred_lr4 = gb_lr4.predict(X_train)\n",
    "train_pred_lr5 = gb_lr5.predict(X_train)\n",
    "\n",
    "test_pred_lr1 = gb_lr1.predict(X_test)\n",
    "test_pred_lr2 = gb_lr2.predict(X_test)\n",
    "test_pred_lr3 = gb_lr3.predict(X_test)\n",
    "test_pred_lr4 = gb_lr4.predict(X_test)\n",
    "test_pred_lr5 = gb_lr5.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, LR : 0.0001\n",
      "정확도(accuracy): 0.9413145539906104\n",
      "재현율/민감도(recall): 0.9887640449438202\n",
      "정밀도(precision): 0.9230769230769231\n",
      "F1-score: 0.9547920433996384\n",
      "==============================\n",
      "Test, LR : 0.0001\n",
      "정확도(accuracy): 0.916083916083916\n",
      "재현율/민감도(recall): 0.9888888888888889\n",
      "정밀도(precision): 0.89\n",
      "F1-score: 0.9368421052631579\n"
     ]
    }
   ],
   "source": [
    "pmc1(y_train, train_pred_lr1, f'Train, LR : {lr1}')\n",
    "print('='*30)\n",
    "pmc1(y_test, test_pred_lr1, f'Test, LR : {lr1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, LR : 0.001\n",
      "정확도(accuracy): 0.9953051643192489\n",
      "재현율/민감도(recall): 1.0\n",
      "정밀도(precision): 0.9925650557620818\n",
      "F1-score: 0.9962686567164178\n",
      "==============================\n",
      "Test, LR : 0.001\n",
      "정확도(accuracy): 0.958041958041958\n",
      "재현율/민감도(recall): 0.9666666666666667\n",
      "정밀도(precision): 0.9666666666666667\n",
      "F1-score: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "pmc1(y_train, train_pred_lr2, f'Train, LR : {lr2}')\n",
    "print('='*30)\n",
    "pmc1(y_test, test_pred_lr2, f'Test, LR : {lr2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, LR : 0.01\n",
      "정확도(accuracy): 1.0\n",
      "재현율/민감도(recall): 1.0\n",
      "정밀도(precision): 1.0\n",
      "F1-score: 1.0\n",
      "==============================\n",
      "Test, LR : 0.01\n",
      "정확도(accuracy): 0.958041958041958\n",
      "재현율/민감도(recall): 0.9555555555555556\n",
      "정밀도(precision): 0.9772727272727273\n",
      "F1-score: 0.9662921348314608\n"
     ]
    }
   ],
   "source": [
    "pmc1(y_train, train_pred_lr3, f'Train, LR : {lr3}')\n",
    "print('='*30)\n",
    "pmc1(y_test, test_pred_lr3, f'Test, LR : {lr3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, LR : 0.1\n",
      "정확도(accuracy): 1.0\n",
      "재현율/민감도(recall): 1.0\n",
      "정밀도(precision): 1.0\n",
      "F1-score: 1.0\n",
      "==============================\n",
      "Test, LR : 0.1\n",
      "정확도(accuracy): 0.958041958041958\n",
      "재현율/민감도(recall): 0.9555555555555556\n",
      "정밀도(precision): 0.9772727272727273\n",
      "F1-score: 0.9662921348314608\n"
     ]
    }
   ],
   "source": [
    "pmc1(y_train, train_pred_lr4, f'Train, LR : {lr4}')\n",
    "print('='*30)\n",
    "pmc1(y_test, test_pred_lr4, f'Test, LR : {lr4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, LR : 0.5\n",
      "정확도(accuracy): 1.0\n",
      "재현율/민감도(recall): 1.0\n",
      "정밀도(precision): 1.0\n",
      "F1-score: 1.0\n",
      "==============================\n",
      "Test, LR : 0.5\n",
      "정확도(accuracy): 0.965034965034965\n",
      "재현율/민감도(recall): 0.9666666666666667\n",
      "정밀도(precision): 0.9775280898876404\n",
      "F1-score: 0.9720670391061451\n"
     ]
    }
   ],
   "source": [
    "pmc1(y_train, train_pred_lr5, f'Train, LR : {lr5}')\n",
    "print('='*30)\n",
    "pmc1(y_test, test_pred_lr5, f'Test, LR : {lr5}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV 이용해 최적의 하이퍼파라미터 찾기\n",
    "#### RandomizedSearchCV 생성\n",
    "- n_estimators\n",
    "- learning_rate\n",
    "- max_depth\n",
    "- subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=4, estimator=GradientBoostingClassifier(random_state=0),\n",
       "                   n_iter=60, n_jobs=-1,\n",
       "                   param_distributions={'learning_rate': [0.001, 0.01, 0.05,\n",
       "                                                          0.1, 0.5],\n",
       "                                        'max_depth': [1, 2, 3],\n",
       "                                        'n_estimators': [1000, 2000, 3000, 4000,\n",
       "                                                         5000],\n",
       "                                        'subsample': [0.5, 0.6, 0.7, 0.8, 0.9,\n",
       "                                                      1.0]},\n",
       "                   scoring='accuracy')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "gb = GradientBoostingClassifier(random_state = 0)\n",
    "params = {\n",
    "    'n_estimators' : [1000, 2000, 3000, 4000, 5000],\n",
    "    'learning_rate' : [0.001, 0.01, 0.05, 0.1, 0.5],\n",
    "    'max_depth' : [1, 2, 3],\n",
    "    'subsample' : [0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "rs = RandomizedSearchCV(gb, params, n_iter = 60, scoring = 'accuracy', cv = 4, n_jobs = -1)\n",
    "rs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score: 0.9742108975489332\n",
      "best_params: {'subsample': 0.7, 'n_estimators': 5000, 'max_depth': 3, 'learning_rate': 0.1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>6.444808</td>\n",
       "      <td>0.120626</td>\n",
       "      <td>0.009245</td>\n",
       "      <td>0.003895</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'subsample': 0.7, 'n_estimators': 5000, 'max_...</td>\n",
       "      <td>0.953271</td>\n",
       "      <td>0.981308</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.974211</td>\n",
       "      <td>0.012090</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2.565031</td>\n",
       "      <td>0.105345</td>\n",
       "      <td>0.003997</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'subsample': 0.6, 'n_estimators': 1000, 'max_...</td>\n",
       "      <td>0.943925</td>\n",
       "      <td>0.990654</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.974211</td>\n",
       "      <td>0.017912</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.665778</td>\n",
       "      <td>1.014146</td>\n",
       "      <td>0.021236</td>\n",
       "      <td>0.022948</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'subsample': 0.5, 'n_estimators': 3000, 'max_...</td>\n",
       "      <td>0.953271</td>\n",
       "      <td>0.971963</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.971874</td>\n",
       "      <td>0.011374</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "41       6.444808      0.120626         0.009245        0.003895   \n",
       "44       2.565031      0.105345         0.003997        0.000707   \n",
       "2       15.665778      1.014146         0.021236        0.022948   \n",
       "\n",
       "   param_subsample param_n_estimators param_max_depth param_learning_rate  \\\n",
       "41             0.7               5000               3                 0.1   \n",
       "44             0.6               1000               3                 0.1   \n",
       "2              0.5               3000               2                0.05   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "41  {'subsample': 0.7, 'n_estimators': 5000, 'max_...           0.953271   \n",
       "44  {'subsample': 0.6, 'n_estimators': 1000, 'max_...           0.943925   \n",
       "2   {'subsample': 0.5, 'n_estimators': 3000, 'max_...           0.953271   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  mean_test_score  \\\n",
       "41           0.981308           0.981132           0.981132         0.974211   \n",
       "44           0.990654           0.981132           0.981132         0.974211   \n",
       "2            0.971963           0.981132           0.981132         0.971874   \n",
       "\n",
       "    std_test_score  rank_test_score  \n",
       "41        0.012090                1  \n",
       "44        0.017912                1  \n",
       "2         0.011374                3  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('best_score:', rs.best_score_)\n",
    "print('best_params:', rs.best_params_)\n",
    "\n",
    "pd.DataFrame(rs.cv_results_).sort_values('rank_test_score').head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22    0.430558\n",
       "7     0.156076\n",
       "27    0.101677\n",
       "20    0.093673\n",
       "23    0.056623\n",
       "26    0.034179\n",
       "21    0.025567\n",
       "1     0.024364\n",
       "13    0.016412\n",
       "24    0.015846\n",
       "6     0.011620\n",
       "10    0.005720\n",
       "16    0.004267\n",
       "12    0.003865\n",
       "11    0.003644\n",
       "5     0.002104\n",
       "0     0.001961\n",
       "3     0.001849\n",
       "25    0.001665\n",
       "2     0.001515\n",
       "9     0.001363\n",
       "19    0.001280\n",
       "18    0.001135\n",
       "15    0.000969\n",
       "28    0.000749\n",
       "17    0.000556\n",
       "8     0.000291\n",
       "29    0.000209\n",
       "14    0.000190\n",
       "4     0.000070\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = rs.best_estimator_\n",
    "fi = pd.Series(best_model.feature_importances_)\n",
    "\n",
    "fi.sort_values(ascending= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost(Extra Gradient Boost)\n",
    "- Gradient Boost 알고리즘을 기반으로 개선해서 분산환경에서도 실행할 수 있도록 구현된 모델\n",
    "- Gradient Boost의 단점인 느린 수행 시간을 해결, 과적합을 제어할 수 있는 규제들을 제공하여 성능을 높임\n",
    "- 회귀와 분류 모두 지원\n",
    "- 두가지 개발 방법\n",
    "    - Scikit-learn 래퍼 XGBoost 모듈 사용\n",
    "    - 파이썬 래퍼 XGBoost 모듈 사용\n",
    "- 설치\n",
    "    - conda install -y -c anaconda py-xgboost\n",
    "    - pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-learn 래퍼 XGBoost\n",
    "- XGBoost를 Scikit-learn 프레임워크와 연동할 수 있도록 개발\n",
    "- Scikit-learn의 Estimator들과 동일한 패턴으로 코드를 작성할 수 있다\n",
    "- GridSearchCV나 Pipeline 등 Scikit-learn이 제공하는 다양한 유틸리티들을 사용할 수 있다\n",
    "- XGBClassifier: 분류\n",
    "- XGBRegressor: 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 주요 매개변수\n",
    "- learning_rate: 학습률, 보통 0.01 ~ 0.2 사이의 값 사용\n",
    "- n_estimators: weak tree 개수\n",
    "- DecisionTree관련 하이퍼파라미터들"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=2, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=500, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=0, ...)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(n_estimators = 500, learning_rate = 0.01, max_depth = 2, random_state = 0)\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22    0.317715\n",
       "7     0.191484\n",
       "27    0.150696\n",
       "20    0.077119\n",
       "23    0.050489\n",
       "11    0.037051\n",
       "26    0.029967\n",
       "21    0.025489\n",
       "0     0.022118\n",
       "13    0.016181\n",
       "6     0.015403\n",
       "1     0.013993\n",
       "10    0.012032\n",
       "8     0.011944\n",
       "24    0.009557\n",
       "29    0.005800\n",
       "12    0.005580\n",
       "28    0.005041\n",
       "18    0.002342\n",
       "16    0.000000\n",
       "17    0.000000\n",
       "19    0.000000\n",
       "14    0.000000\n",
       "9     0.000000\n",
       "5     0.000000\n",
       "4     0.000000\n",
       "25    0.000000\n",
       "3     0.000000\n",
       "2     0.000000\n",
       "15    0.000000\n",
       "dtype: float32"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi = pd.Series(xgb.feature_importances_)\n",
    "\n",
    "fi.sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도(accuracy): 0.9953051643192489\n",
      "재현율/민감도(recall): 0.9962546816479401\n",
      "정밀도(precision): 0.9962546816479401\n",
      "F1-score: 0.9962546816479401\n",
      "==============================\n",
      "정확도(accuracy): 0.951048951048951\n",
      "재현율/민감도(recall): 0.9555555555555556\n",
      "정밀도(precision): 0.9662921348314607\n",
      "F1-score: 0.9608938547486034\n"
     ]
    }
   ],
   "source": [
    "pmc1(y_train, xgb.predict(X_train))\n",
    "print('='*30)\n",
    "pmc1(y_test, xgb.predict(X_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "57bc2b6ce032b5f0e93daa91901b7ea38a856826ef43aa9e95b6d3999f5310df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
