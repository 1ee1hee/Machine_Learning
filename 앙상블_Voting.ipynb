{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble - Voting 방식\n",
    "- 서로 다른 종류의 알고리즘들을 결합하여 다수결 방식으로 최종 결과를 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting의 유형(분류)\n",
    "- 비슷한 성능을 내면서 서로 다른 예측을 하는 것이 많은 모델들을 묶어줄 때 성능이 올라감\n",
    "\n",
    "### 1. hard voting\n",
    "- 다수의 추정기가 결정한 예측값들 중 많은 것을 선택\n",
    "![image](https://i.stack.imgur.com/W7UmY.png)\n",
    "\n",
    "### 2. soft voting\n",
    "- 다수의 추정기에서 각 레이블별 예측한 확률들의 평균을 내서 높은 레이블값을 결과값으로 선택하는 방식\n",
    "![image](https://velog.velcdn.com/images/one_step/post/b20c0713-f226-42c2-b1e7-b576ea1088e6/image.png)\n",
    "\n",
    "- 일반적으로 soft voting이 성능이 좋다\n",
    "- 비슷한 성능을 내면서 서로 다른 예측을 하는 것이 많은 모델들을 묶을 때 성능이 올라간다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VotingClassifier 클래스 이용\n",
    "- 매개변수\n",
    "    - estimators: 앙상블할 모델 설정(\"추정기이름\", 추정기)의 튜플을 리스트로 묶어서 전달\n",
    "    - voting: voting 방식. hard(기본값), soft 지정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 위스콘신 유방암 데이터셋으로 실습\n",
    "### import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋 로딩 및 train/test set 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_breast_cancer(return_X_y = True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data 전처리\n",
    "- SVM, KNN, LogisticRegression은 Feature Scaling 전처리 데이터를 사용\n",
    "- RandomForest, XGBoost는 DecisionTree 가반이므로 Feature Scaling이 필요없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델들 생성, 학습, 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적의 하이퍼파라미터를 찾은 것으로 가정\n",
    "knn = Pipeline(\n",
    "    steps = [('scaler', StandardScaler()),\n",
    "             ('knn', KNeighborsClassifier(n_neighbors = 5))\n",
    "             ]\n",
    ")\n",
    "\n",
    "svc = Pipeline(\n",
    "    steps = [('scaler', StandardScaler()),\n",
    "             ('svc', SVC(random_state = 0, probability = True))\n",
    "             ]\n",
    ")\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators = 200, max_depth = 3, random_state = 0)\n",
    "xgb = XGBClassifier(n_estimators = 500, learning_rate = 0.01, max_depth = 1, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN의 train set\n",
      "정확도(accuracy): 0.9788732394366197\n",
      "재현율/민감도(recall): 0.9850187265917603\n",
      "정밀도(precision): 0.9813432835820896\n",
      "F1-score: 0.9831775700934579\n",
      "------------------------------\n",
      "KNN의 test set\n",
      "정확도(accuracy): 0.951048951048951\n",
      "재현율/민감도(recall): 0.9888888888888889\n",
      "정밀도(precision): 0.9368421052631579\n",
      "F1-score: 0.9621621621621621\n",
      "==============================\n",
      "SVM의 train set\n",
      "정확도(accuracy): 0.9929577464788732\n",
      "재현율/민감도(recall): 0.9962546816479401\n",
      "정밀도(precision): 0.9925373134328358\n",
      "F1-score: 0.9943925233644859\n",
      "------------------------------\n",
      "SVM의 test set\n",
      "정확도(accuracy): 0.958041958041958\n",
      "재현율/민감도(recall): 0.9666666666666667\n",
      "정밀도(precision): 0.9666666666666667\n",
      "F1-score: 0.9666666666666667\n",
      "==============================\n",
      "Random Forest의 train set\n",
      "정확도(accuracy): 0.9835680751173709\n",
      "재현율/민감도(recall): 0.9962546816479401\n",
      "정밀도(precision): 0.9779411764705882\n",
      "F1-score: 0.987012987012987\n",
      "------------------------------\n",
      "Random Forest의 test set\n",
      "정확도(accuracy): 0.9440559440559441\n",
      "재현율/민감도(recall): 0.9555555555555556\n",
      "정밀도(precision): 0.9555555555555556\n",
      "F1-score: 0.9555555555555556\n",
      "==============================\n",
      "XGBoost의 train set\n",
      "정확도(accuracy): 0.9859154929577465\n",
      "재현율/민감도(recall): 0.9925093632958801\n",
      "정밀도(precision): 0.9851301115241635\n",
      "F1-score: 0.9888059701492536\n",
      "------------------------------\n",
      "XGBoost의 test set\n",
      "정확도(accuracy): 0.951048951048951\n",
      "재현율/민감도(recall): 0.9777777777777777\n",
      "정밀도(precision): 0.946236559139785\n",
      "F1-score: 0.9617486338797814\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "from metrics import print_metrics_classification as pmc\n",
    "\n",
    "estimators = [\n",
    "    ('KNN', knn),\n",
    "    ('SVM', svc),\n",
    "    ('Random Forest', rfc),\n",
    "    ('XGBoost', xgb)\n",
    "]\n",
    "\n",
    "# 각 모델이 test dataset에 대해 추론한 결과를 저장\n",
    "test_pred_dict = {}\n",
    "for name, model in estimators:\n",
    "    model.fit(X_train, y_train)\n",
    "    train_pred = model.predict(X_train)\n",
    "    test_pred = model.predict(X_test)\n",
    "    test_pred_dict[name] = test_pred\n",
    "    \n",
    "    pmc(y_train, train_pred, f'{name}의 train set')\n",
    "    print('-'*30)\n",
    "    pmc(y_test, test_pred, f'{name}의 test set')\n",
    "    print('='*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 앙상블 상관관계\n",
    "- 상관관계가 높은 모델은 앙상블에 포함시키는 것이 바람직 하지 않음\n",
    "- 모델간 상관관계가 높다는 것은 두 모델이 동일한 예측을 한다는 것이다. 예측을 하는 모델은 의미가 없다\n",
    "- Voting방식(다수결 투표방식)의 앙상블은 각각 좋은 성능을 내지만 다른 예측을 하는 다양한 모델을 모아서 하는 것이 좋다. 대부분의 모델들이 동일한 예측을 만든다면 새로운 모델을 추가해 얻는 이득이 적다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델간의 상관관계 확인\n",
    "- 각 모델의 예측 결과를 이용해 상관계수를 구한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KNN</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.895618</td>\n",
       "      <td>0.926280</td>\n",
       "      <td>0.938373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.895618</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.880084</td>\n",
       "      <td>0.925128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.926280</td>\n",
       "      <td>0.880084</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.955492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.938373</td>\n",
       "      <td>0.925128</td>\n",
       "      <td>0.955492</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    KNN       SVM  Random Forest   XGBoost\n",
       "KNN            1.000000  0.895618       0.926280  0.938373\n",
       "SVM            0.895618  1.000000       0.880084  0.925128\n",
       "Random Forest  0.926280  0.880084       1.000000  0.955492\n",
       "XGBoost        0.938373  0.925128       0.955492  1.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(test_pred_dict)\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **개별 성능이 가장 좋은 모델을 기준으로 상관계수가 낮은 모델을 선택해서 Voting 한다**\n",
    "- 성능: SVM\n",
    "- voting: KNN, RandomForest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VotingClassifier로 앙상블\n",
    "- estimators\n",
    "    - 앙상블할 모델들을 묶어서 전달 [('모델이름', 모델객체), ...]\n",
    "- voting(voting 방식)\n",
    "    - 'hard'(기본 - hard voting), 'soft' - soft voting\n",
    "    - 분류일때만 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = [\n",
    "    ('svm', svc), \n",
    "    ('knn', knn), \n",
    "    ('rfc', rfc)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### hard voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "voting_hard = VotingClassifier(est)\n",
    "result = cross_val_score(voting_hard, X_train, y_train, cv = 4, scoring = 'accuracy', n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.97196262 0.98130841 1.         0.98113208]\n",
      "0.9836007758772702\n"
     ]
    }
   ],
   "source": [
    "print(result)\n",
    "print(result.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.951048951048951"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test set으로 최종 평가\n",
    "voting_hard.fit(X_train, y_train)\n",
    "test_pred = voting_hard.predict(X_test)\n",
    "accuracy_score(y_test, test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### soft voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_soft = VotingClassifier(est, voting = 'soft')\n",
    "result2 = cross_val_score(voting_soft, X_train, y_train, cv = 4, scoring = 'accuracy', n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98130841 0.98130841 0.99056604 0.99056604]\n",
      "0.9859372244754011\n"
     ]
    }
   ],
   "source": [
    "print(result2)\n",
    "print(result2.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.951048951048951"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_soft.fit(X_train, y_train)\n",
    "accuracy_score(y_test, voting_soft.predict(X_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "57bc2b6ce032b5f0e93daa91901b7ea38a856826ef43aa9e95b6d3999f5310df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
