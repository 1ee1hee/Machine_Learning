{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 최적화(Optimize)\n",
    "- 모델이 예측한 결과와 정답간의 차이(오차)를 가장 적게 만드는 Parameter를 찾는 과정을 최적화라 함\n",
    "- 모델의 예측값 실제 값의 차이를 계산하는 함수를 만들고 그 값이 최소가 되는 지점을 찾는 작업을 한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 최적화 문제\n",
    "- 함수 f(w)의 값을 최소화(또는 최대한) 하는 변수 w(파라미터)를 찾는 것\n",
    "$$\n",
    "w_{i} = \\arg \\min_w f(w) \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 손실함수(Loss Function), 비용함수(Cost Function), 목적함수(Object Fuction), 오차함수(Error Function)\n",
    "- 모델의 예측한 값과 실제값 사이의 차이를 정의하는 함수로 모델이 학습을 할 때 사용된다\n",
    "- 이 함수의 반환값(Loss)을 최소화하는 파라미터를 찾는 것이 최적화의 목적\n",
    "- 해결하려는 문제에 맞춰 Loss 함수를 정의\n",
    "    - Classification(분류)의 경우 cross entropy를 사용\n",
    "    - Regression(회귀)의 경우 MSE(Mean Squared Error)를 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최적화 문제를 해결하는 방법\n",
    "- Loss 함수 최적화 함수를 찾는다\n",
    "    - Loss를 최소화하는 weight들을 찾는 함수(공식)을 찾는다\n",
    "    - Feature와 sample수가 많아 질 수록 계산량이 급증\n",
    "    - 최적화 함수가 없는 Loss함수도 있다\n",
    "- **경사하강법(Gradient Descent)**\n",
    "    - 값을 조금씩 조금씩 조정해나가면서 최소값을 찾는다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 경사하강법(Gradient Descent)\n",
    "- 다양한 종류의 문제에서 최적의 해법을 찾을 수 있는 **일반적인 최적화 알고리즘**\n",
    "- 손실함수를 최소화하는 파라미터를 찾기위해 반복해서 조정 \n",
    "    - 파라미터 벡터 $W$에 대해 손실함수의 현재 gradient(경사,기울기)를 계산\n",
    "    - gradient가 감소하는 방향으로 벡터 $W$를 조정\n",
    "    - gradient가 0이 될때 까지 반복\n",
    "- gradient가 양수이면 loss와 weight가 비례관계란 의미이므로 loss를 더 작게 하려면 weight가 작아져야 한다    \n",
    "- gradient가 음수이면 loss와 weight가 반비례관계란 의미이므로 loss를 더 작게 하려면 weight가 커져야 한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://androidkt.com/wp-content/uploads/2022/09/Learning-Rate.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파라미터 조정\n",
    "\n",
    "$$\n",
    "W_{new} = W-\\alpha\\frac{\\partial}{\\partial {W}}cost(W)\n",
    "$$\n",
    "\n",
    "\n",
    "$W$: 파라미터<br>$\\alpha$:학습률\n",
    "\n",
    "- 학습률 (Learning rate)\n",
    "    - 기울기에 따라 이동할 step의 크기. 경사하강법 알고리즘에서 지정해야하는 하이퍼파라미터\n",
    "    - 학습률을 너무 작게 잡으면 최소값에 수렴하기 위해 많은 반복을 진행해야해 시간이 오래걸림\n",
    "    - 학습률을 너무 크게 잡으면 왔다 갔다 하다가 오히려 더 큰 값으로 발산하여 최소값에 수렴하지 못함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(weight):\n",
    "    return (weight-1)**2 + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위의 loss함수의 도함수\n",
    "def derived_loss(weight):\n",
    "    return 2*(weight-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w=1, 오차: 2\n",
      "w=1, 기울기: 0\n"
     ]
    }
   ],
   "source": [
    "print('w=1, 오차:', loss(1))\n",
    "print('w=1, 기울기:', derived_loss(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(5), derived_loss(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = 5\n",
    "lr = 0.1\n",
    "new_weight = weight - lr*derived_loss(weight)\n",
    "new_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.56"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = 4.2\n",
    "lr = 0.1\n",
    "new_weight = weight - lr*derived_loss(weight)\n",
    "new_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.048"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = 3.56\n",
    "lr = 0.1\n",
    "new_weight = weight - lr*derived_loss(weight)\n",
    "new_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 반복문을 이용해 gradient가 0이 되는 지점의 weight 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "learning_rate = 0.4\n",
    "\n",
    "max_iter = 100\n",
    "\n",
    "weight = np.random.randint(-2, 3)\n",
    "weight_list = [weight]\n",
    "iter_cnt = 0\n",
    "\n",
    "while True:\n",
    "    if derived_loss(weight) == 0:\n",
    "        break\n",
    "    if iter_cnt == max_iter:\n",
    "        break\n",
    "    \n",
    "    weight = weight - learning_rate * derived_loss(weight)\n",
    "    weight_list.append(weight)\n",
    "    iter_cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "[2, 1.2, 1.04, 1.008, 1.0016, 1.00032, 1.000064, 1.0000128, 1.00000256, 1.000000512, 1.0000001024, 1.00000002048, 1.000000004096, 1.0000000008192, 1.00000000016384, 1.000000000032768, 1.0000000000065536, 1.0000000000013107, 1.0000000000002622, 1.0000000000000524, 1.0000000000000104, 1.000000000000002, 1.0000000000000004, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print(iter_cnt)\n",
    "print(weight_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.01, 2.0, 2.0100000000000002)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(0.9), loss(1.0), loss(1.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "57bc2b6ce032b5f0e93daa91901b7ea38a856826ef43aa9e95b6d3999f5310df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
