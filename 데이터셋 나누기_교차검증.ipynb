{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 성능 평가를 위한 데이터 셋 분리\n",
    "## 데이터셋(Dataset)\n",
    "- Train 데이터셋 (훈련 / 학습 데이터셋)\n",
    "    - 모델을 학습시킬 때 사용할 데이터셋\n",
    "- Validation 데이터셋 (검증 데이터셋)\n",
    "    - 모델의 성능 중간 검증을 위한 데이터셋\n",
    "- Test 데이터셋 (평가 데이터셋)\n",
    "    - 모델의 성능을 최종적으로 측정하기 위한 데이터셋\n",
    "    - `Test 데이터셋은 마지막에 모델의 성능을 측정하는 용도로 한번만 사용`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hold Out - Data분리 방식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://blog.kakaocdn.net/dn/R5F4R/btqHb0lGapZ/Cupp4u4JJLbKXKKhfgfhM1/img.png)\n",
    "- 데이터셋을 Train set, Validation set, Test set으로 나눔\n",
    "- sklearn.model_selecton.train_test_split() 함수 사용\n",
    "    - 하나의 데이터셋을 2분할 하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = load_iris(return_X_y = True)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train / Test set 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120, 4), (30, 4))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size = 0.2,\n",
    "                                                    stratify = y,\n",
    "                                                    random_state = 0\n",
    "                                                    )\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train / Validation / Test set 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 4) (24, 4) (30, 4)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.2, stratify = y_train, random_state = 0)\n",
    "print(X_train.shape, X_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 생성, 평가\n",
    "- max_depth = 정수\n",
    "    - 하이퍼파라미터 : 모델의 성능에 영향을 주는 파라미터 값으로 개발자가 설정하는 값\n",
    "    - 파라미터 : 머신러닝 모델의 파라미터 -> 학습을 통해서 찾는 모델의 가중치 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "tree = DecisionTreeClassifier(max_depth = 5, random_state = 0)\n",
    "\n",
    "# 학습\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# 검증\n",
    "pred_train = tree.predict(X_train)\n",
    "pred_val = tree.predict(X_val)\n",
    "\n",
    "# 정확도 계산\n",
    "train_acc = accuracy_score(y_train, pred_train)\n",
    "val_acc = accuracy_score(y_val, pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth: 5\n",
      "train 정확도: 1.0\n",
      "val 정확도: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"max_depth:\", 5)\n",
    "print(\"train 정확도:\", train_acc)\n",
    "print(\"val 정확도:\", val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testset으로 최종검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testset 정확도:  0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "pred_test = tree.predict(X_test)\n",
    "test_acc = accuracy_score(y_test, pred_test)\n",
    "print(\"Testset 정확도: \", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hold out 방식의 단점\n",
    "- train / validation / test set이 어떻게 나눠 지냐에 따라 결과가 다름\n",
    "    - 데이터가 적을 경우 문제가 발생할 수 있다\n",
    "        - 이상치에 대한 영향을 많이 받음\n",
    "        - 다양한 패턴을 찾을 수 없어 새로운 데이터에 대한 예측 능력 떨어짐\n",
    "- Hold out방식은 데이터의 양이 많을 때 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-겹 교차검증 (K-Fold Cross Validation) - Data 분리 방식\n",
    "1. 데이터셋을 설정한 K개로 나눔\n",
    "2. K개 중 하나를 검증세트로 나머지를 훈련세트로 하여 모델을 학습하고 평가\n",
    "3. K개 모두 한번씩 검증 세트가 되도록 K번 반복해 모델을 학습, 평가지표들을 평균내서 모델의 성능을 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://blog.kakaocdn.net/dn/br92jB/btrnwoqmQVy/qAr76wPpnYkoveJaZAXXHk/img.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터양이 충분치 않을 때 사용\n",
    "- 보통 Fold를 나눌 때 2.5 : 7.5 또는 2 : 8 비율이 되게 하기 위해 4개 또는 5개 fold로 나눈다\n",
    "- 종류\n",
    "    - KFold\n",
    "        - 회귀문제의 Dataset을 분리할 때 사용 (순서대로 동일한 개수로 나눔)\n",
    "    - StratifiedKFold\n",
    "        - 분류문제의 Dataset을 분리할 때 사용 (동일한 비율로 나눔)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Boston Housing DataSet\n",
    "> 보스톤의 지역별 집값 데이터셋\n",
    "> \n",
    ">  - CRIM\t: 지역별 범죄 발생률\n",
    ">  - ZN\t: 25,000 평방피트를 초과하는 거주지역의 비율\n",
    ">  - INDUS: 비상업지역 토지의 비율\n",
    ">  - CHAS\t: 찰스강에 대한 더미변수(강의 경계에 위치한 경우는 1, 아니면 0)\n",
    ">  - NOX\t: 일산화질소 농도\n",
    ">  - RM\t: 주택 1가구당 평균 방의 개수\n",
    ">  - AGE\t: 1940년 이전에 건축된 소유주택의 비율\n",
    ">  - DIS\t: 5개의 보스턴 고용센터까지의 접근성 지수\n",
    ">  - RAD\t: 고속도로까지의 접근성 지수\n",
    ">  - TAX\t: 10,000 달러 당 재산세율\n",
    ">  - PTRATIO : 지역별 교사 한명당 학생 비율\n",
    ">  - B\t: 지역의 흑인 거주 비율\n",
    ">  - LSTAT: 하위계층의 비율(%)\n",
    ">  \n",
    ">  - MEDV\t: Target.  지역의 주택가격 중앙값 (단위: $1,000)\n",
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "boston = load_boston()\n",
    "data = boston.data\n",
    "target = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((506, 13), (506,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "        18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2]),\n",
       " (array([ 5. ,  5.6,  6.3,  7. ,  7.2,  7.4,  7.5,  8.1,  8.3,  8.4,  8.5,\n",
       "          8.7,  8.8,  9.5,  9.6,  9.7, 10.2, 10.4, 10.5, 10.8, 10.9, 11. ,\n",
       "         11.3, 11.5, 11.7, 11.8, 11.9, 12. , 12.1, 12.3, 12.5, 12.6, 12.7,\n",
       "         12.8, 13. , 13.1, 13.2, 13.3, 13.4, 13.5, 13.6, 13.8, 13.9, 14. ,\n",
       "         14.1, 14.2, 14.3, 14.4, 14.5, 14.6, 14.8, 14.9, 15. , 15.1, 15.2,\n",
       "         15.3, 15.4, 15.6, 15.7, 16. , 16.1, 16.2, 16.3, 16.4, 16.5, 16.6,\n",
       "         16.7, 16.8, 17. , 17.1, 17.2, 17.3, 17.4, 17.5, 17.6, 17.7, 17.8,\n",
       "         17.9, 18. , 18.1, 18.2, 18.3, 18.4, 18.5, 18.6, 18.7, 18.8, 18.9,\n",
       "         19. , 19.1, 19.2, 19.3, 19.4, 19.5, 19.6, 19.7, 19.8, 19.9, 20. ,\n",
       "         20.1, 20.2, 20.3, 20.4, 20.5, 20.6, 20.7, 20.8, 20.9, 21. , 21.1,\n",
       "         21.2, 21.4, 21.5, 21.6, 21.7, 21.8, 21.9, 22. , 22.1, 22.2, 22.3,\n",
       "         22.4, 22.5, 22.6, 22.7, 22.8, 22.9, 23. , 23.1, 23.2, 23.3, 23.4,\n",
       "         23.5, 23.6, 23.7, 23.8, 23.9, 24. , 24.1, 24.2, 24.3, 24.4, 24.5,\n",
       "         24.6, 24.7, 24.8, 25. , 25.1, 25.2, 25.3, 26.2, 26.4, 26.5, 26.6,\n",
       "         26.7, 27. , 27.1, 27.5, 27.9, 28. , 28.1, 28.2, 28.4, 28.5, 28.6,\n",
       "         28.7, 29. , 29.1, 29.4, 29.6, 29.8, 29.9, 30.1, 30.3, 30.5, 30.7,\n",
       "         30.8, 31. , 31.1, 31.2, 31.5, 31.6, 31.7, 32. , 32.2, 32.4, 32.5,\n",
       "         32.7, 32.9, 33. , 33.1, 33.2, 33.3, 33.4, 33.8, 34.6, 34.7, 34.9,\n",
       "         35.1, 35.2, 35.4, 36. , 36.1, 36.2, 36.4, 36.5, 37. , 37.2, 37.3,\n",
       "         37.6, 37.9, 38.7, 39.8, 41.3, 41.7, 42.3, 42.8, 43.1, 43.5, 43.8,\n",
       "         44. , 44.8, 45.4, 46. , 46.7, 48.3, 48.5, 48.8, 50. ]),\n",
       "  array([ 2,  1,  1,  2,  3,  1,  1,  1,  2,  2,  2,  1,  2,  1,  1,  1,  3,\n",
       "          2,  2,  1,  2,  1,  1,  1,  2,  2,  2,  1,  1,  1,  1,  1,  3,  1,\n",
       "          1,  4,  1,  3,  4,  2,  2,  5,  2,  1,  3,  1,  2,  2,  3,  2,  1,\n",
       "          3,  3,  1,  3,  1,  2,  5,  1,  1,  3,  2,  1,  1,  2,  2,  2,  2,\n",
       "          1,  3,  3,  1,  3,  3,  1,  1,  5,  1,  1,  1,  3,  2,  3,  4,  2,\n",
       "          3,  2,  4,  2,  4,  2,  5,  6,  4,  5,  2,  3,  4,  5,  5,  2,  4,\n",
       "          4,  3,  6,  2,  3,  2,  3,  2,  5,  5,  2,  2,  7,  2,  3,  7,  1,\n",
       "          5,  2,  2,  3,  5,  2,  4,  4,  4,  7,  4,  4,  2,  1,  2,  4,  4,\n",
       "          5,  2,  3,  1,  3,  4,  3,  2,  3,  4,  8,  1,  1,  1,  1,  2,  1,\n",
       "          3,  1,  1,  2,  4,  2,  1,  1,  1,  2,  1,  1,  3,  2,  2,  1,  2,\n",
       "          2,  1,  3,  1,  1,  1,  1,  1,  1,  1,  2,  2,  1,  2,  1,  1,  1,\n",
       "          1,  1,  1,  2,  2,  1,  2,  1,  1,  1,  3,  1,  1,  2,  1,  1,  2,\n",
       "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "          1,  1,  1,  1,  1,  1,  1, 16], dtype=int64)))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target[:20], np.unique(target, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22.532806324110677, 21.2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(target), np.median(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KFold\n",
    "- 지정한 개수(K)만큼 분할\n",
    "- Raw dataset의 순서를 유지하면서 지정한 개수로 분할\n",
    "- 회귀 문제일때 사옹\n",
    "- KFold(n_splits = K)\n",
    "    - 몇개의 Fold로 나눌지 지정\n",
    "- KFold객체.split(데이터셋)\n",
    "    - 데이터셋을 지정한 K개 나눴을때 train/test set에 포함될 데이터의 index들을 반환하는 generator 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Generator란\n",
    ">     - 연속된 값을 제공(생성)하는 객체. 연속된 값을 한번에 메모리에 저장하지 않고 필요시마다 순서대로 하나씩 제공한다.\n",
    ">     - 함수형식으로 구현하며 return 대신 yield를 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KFold 예제\n",
    "#### Boston housing dataset을 KFold를 이용해 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'generator'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kfold = KFold(n_splits = 5) # K:4 => 7.5 : 2.5, K:5 => 8:2\n",
    "gen = kfold.split(data)\n",
    "print(type(gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n",
       "        115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127,\n",
       "        128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140,\n",
       "        141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
       "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166,\n",
       "        167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179,\n",
       "        180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192,\n",
       "        193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
       "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218,\n",
       "        219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231,\n",
       "        232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244,\n",
       "        245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257,\n",
       "        258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270,\n",
       "        271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
       "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296,\n",
       "        297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309,\n",
       "        310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322,\n",
       "        323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
       "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348,\n",
       "        349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361,\n",
       "        362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374,\n",
       "        375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387,\n",
       "        388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400,\n",
       "        401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413,\n",
       "        414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426,\n",
       "        427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
       "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452,\n",
       "        453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465,\n",
       "        466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478,\n",
       "        479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491,\n",
       "        492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504,\n",
       "        505]),\n",
       " array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "         13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "         26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "         39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "         52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "         65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "         91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KFold를 이용해 교차 검증\n",
    "val_results = []\n",
    "\n",
    "kfold = KFold(n_splits=5)\n",
    "gen = kfold.split(data)\n",
    "\n",
    "for train_idx, test_idx in gen:\n",
    "    X_train, y_train = data[train_idx], target[train_idx]\n",
    "    X_test, y_test = data[test_idx], target[test_idx]\n",
    "    \n",
    "    # 모델 생성, 학습\n",
    "    tree = DecisionTreeRegressor(random_state = 0)\n",
    "    tree.fit(X_train, y_train)\n",
    "    \n",
    "    # 평가\n",
    "    pred_test = tree.predict(X_test)\n",
    "    test_mse = mean_squared_error(y_test, pred_test)\n",
    "    \n",
    "    val_results.append(test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold별 평가결과:  [11.887843137254906, 34.88990099009901, 28.17247524752476, 54.44178217821782, 52.59029702970297]\n",
      "최종결과:  36.39645971655989 6.032947846331832\n"
     ]
    }
   ],
   "source": [
    "print(\"fold별 평가결과: \", val_results)\n",
    "print(\"최종결과: \", np.mean(val_results), np.sqrt(np.mean(val_results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# iris 데이터셋을 KFold 이용해서 cross validation\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "X, y = load_iris(return_X_y = True)\n",
    "\n",
    "kfold_iris = KFold(n_splits = 3)\n",
    "for train_idx, test_idx in kfold_iris.split(X):\n",
    "    X_train, y_train = X[train_idx], y[train_idx]\n",
    "    X_test, y_test = X[test_idx], y[test_idx]\n",
    "    # 모델 생성 및 학습\n",
    "    tree = DecisionTreeClassifier(random_state = 0)\n",
    "    tree.fit(X_train, y_train)\n",
    "    # 검증\n",
    "    pred_test = tree.predict(X_test)\n",
    "    print(accuracy_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StratifiedKFold\n",
    "- 나뉜 fold들에 label들이 같은(또는 거의 같은) 비율로 구성 되도록 나눈다\n",
    "- 각각의 클래스 별로 각각 순서대로 나눈다\n",
    "- 분류 문제일 때 사용\n",
    "- StrarifiedKFold(n_splits = K)\n",
    "    - 몇개의 Fold로 나눌지 지정\n",
    "- StratifiedKFold객체.split(X, y)\n",
    "    - 데이터셋을 지정한 K개 나눴을때 train/test set에 포함될 데이터의 index들을 반환하는 generator 생성\n",
    "    - input(X)와 output(y) dataset을 전달"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([33, 33, 34], dtype=int64))\n",
      "(array([0, 1, 2]), array([33, 34, 33], dtype=int64))\n",
      "(array([0, 1, 2]), array([34, 33, 33], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "X, y = load_iris(return_X_y = True)\n",
    "\n",
    "s_kfold = StratifiedKFold(n_splits = 3)\n",
    "gen = s_kfold.split(X, y)\n",
    "val_results = []\n",
    "\n",
    "for train_idx, test_idx in gen:\n",
    "    X_train, y_train = X[train_idx], y[train_idx]\n",
    "    X_test, y_test = X[test_idx], y[test_idx]\n",
    "    \n",
    "    print(np.unique(y_train, return_counts = True))\n",
    "    \n",
    "    # 모델 생성\n",
    "    tree = DecisionTreeClassifier(random_state = 0)\n",
    "    \n",
    "    # 학습\n",
    "    tree.fit(X_train, y_train)\n",
    "    \n",
    "    # 검증\n",
    "    ## 추론\n",
    "    pred_test = tree.predict(X_test)\n",
    "    acc = accuracy_score(y_test, pred_test)\n",
    "    val_results.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.98, 0.94, 0.98], 0.9666666666666667)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_results, np.mean(val_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_function(X, y, model, n_splits = 5):\n",
    "    s_kfold = StratifiedKFold(n_splits = n_splits)\n",
    "    gen = s_kfold.split(X, y)\n",
    "    \n",
    "    val_results = []\n",
    "    \n",
    "    for train_idx, test_idx in gen:\n",
    "        X_train, y_train = X[train_idx], y[train_idx]\n",
    "        X_test, y_test = X[test_idx], y[test_idx]\n",
    "        \n",
    "        # 학습 \n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # 검증\n",
    "        ## 추론\n",
    "        pred_test = model.predict(X_test)\n",
    "        acc = accuracy_score(y_test, pred_test)\n",
    "        val_results.append(acc)\n",
    "        \n",
    "    return val_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9736842105263158, 0.9473684210526315, 0.9459459459459459, 1.0]\n",
      "0.9667496443812233\n"
     ]
    }
   ],
   "source": [
    "X, y = load_iris(return_X_y = True)\n",
    "model = DecisionTreeClassifier(random_state = 0)\n",
    "result = cross_validation_function(X, y, model, n_splits=4)\n",
    "print(result)\n",
    "print(np.mean(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cross_val_score()\n",
    "- 데이터셋을 K개로 나누고 K번 반복하면서 평가하는 작업을 처리해 주는 함수\n",
    "- 주요매개변수\n",
    "    - estimator : 모델 객체\n",
    "    - X : feature\n",
    "    - y : label\n",
    "    - scoring : 평가지표\n",
    "    - cv : 나눌 개수 (K)\n",
    "        - 정수 : 개수\n",
    "        - KFold 타입 객체\n",
    "- 반환값 : array - 각 반복마다의 평가점수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boston dataset(회귀)\n",
    "# neg_mean_squared_error : 계산한 오차평균에 음수를 붙여서 반환\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "tree_reg = DecisionTreeRegressor(random_state = 0)\n",
    "result1 = cross_val_score(estimator = tree_reg,\n",
    "                          X = data, \n",
    "                          y = target, \n",
    "                          scoring = 'neg_mean_squared_error',\n",
    "                          cv = 4\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13.70937008 66.44086614 52.79198413 41.87055556]\n",
      "43.70319397575304\n"
     ]
    }
   ],
   "source": [
    "print(-result1)\n",
    "print(np.mean(-result1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iris datset(분류)\n",
    "tree_cls = DecisionTreeClassifier(random_state = 0)\n",
    "result2 = cross_val_score(estimator = tree_cls,\n",
    "                          X = X,\n",
    "                          y = y,\n",
    "                          scoring = 'accuracy',\n",
    "                          cv = 4\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.97368421 0.94736842 0.94594595 1.        ]\n",
      "0.9667496443812233\n"
     ]
    }
   ],
   "source": [
    "print(result2)\n",
    "print(np.mean(result2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "57bc2b6ce032b5f0e93daa91901b7ea38a856826ef43aa9e95b6d3999f5310df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
